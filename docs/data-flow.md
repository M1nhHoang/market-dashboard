# Data Flow Documentation

## Overview

Há»‡ thá»‘ng xá»­ lÃ½ dá»¯ liá»‡u theo pipeline hourly vá»›i 5 bÆ°á»›c chÃ­nh:
1. **Crawl** - Thu tháº­p dá»¯ liá»‡u tá»« nhiá»u nguá»“n (raw output)
2. **Transform** - Chuyá»ƒn Ä‘á»•i raw data â†’ unified structure
3. **Process** - Xá»­ lÃ½ events qua 3 layers LLM
4. **Store** - LÆ°u vÃ o database
5. **Serve** - Cung cáº¥p qua API cho frontend

---

## Data Taxonomy

Táº¥t cáº£ dá»¯ liá»‡u Ä‘Æ°á»£c phÃ¢n thÃ nh **3 categories chÃ­nh**:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                        DATA TAXONOMY                                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚      METRICS        â”‚  â”‚       EVENTS        â”‚  â”‚      CALENDAR       â”‚
â”‚   (Time Series)     â”‚  â”‚   (Occurrences)     â”‚  â”‚  (Future Schedule)  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ â€¢ CÃ³ VALUE sá»‘       â”‚  â”‚ â€¢ CÃ³ CONTENT text   â”‚  â”‚ â€¢ CÃ³ DATE tÆ°Æ¡ng lai â”‚
â”‚ â€¢ CÃ³ HISTORY        â”‚  â”‚ â€¢ One-time          â”‚  â”‚ â€¢ CÃ³ FORECAST       â”‚
â”‚ â€¢ Cáº§n TRACK trend   â”‚  â”‚ â€¢ Cáº§n ANALYZE (LLM) â”‚  â”‚ â€¢ Cáº§n REMIND        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Examples:           â”‚  â”‚ Examples:           â”‚  â”‚ Examples:           â”‚
â”‚ - Exchange rate     â”‚  â”‚ - SBV news          â”‚  â”‚ - FOMC meeting      â”‚
â”‚ - Interbank rates   â”‚  â”‚ - Press releases    â”‚  â”‚ - VN CPI release    â”‚
â”‚ - Policy rates      â”‚  â”‚ - Announcements     â”‚  â”‚ - Fed decision      â”‚
â”‚ - Gold price        â”‚  â”‚ - Circulars         â”‚  â”‚ - GDP report        â”‚
â”‚ - CPI               â”‚  â”‚                     â”‚  â”‚                     â”‚
â”‚ - OMO volumes       â”‚  â”‚                     â”‚  â”‚                     â”‚
â”‚ - Fed rate (future) â”‚  â”‚                     â”‚  â”‚                     â”‚
â”‚ - DXY (future)      â”‚  â”‚                     â”‚  â”‚                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚                        â”‚                        â”‚
         â–¼                        â–¼                        â–¼
   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”           â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”           â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
   â”‚indicators â”‚           â”‚  events   â”‚           â”‚ calendar  â”‚
   â”‚  (table)  â”‚           â”‚  (table)  â”‚           â”‚  (table)  â”‚
   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜           â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜           â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## High-Level Flow

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                         HOURLY PIPELINE                                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚                        DATA SOURCES                              â”‚
    â”‚                                                                  â”‚
    â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
    â”‚   â”‚   SBV   â”‚  â”‚  News   â”‚  â”‚Calendar â”‚  â”‚     Global      â”‚   â”‚
    â”‚   â”‚ Crawler â”‚  â”‚ Crawler â”‚  â”‚ Crawler â”‚  â”‚    Crawler      â”‚   â”‚
    â”‚   â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
    â”‚        â”‚            â”‚            â”‚                â”‚            â”‚
    â”‚        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜            â”‚
    â”‚                             â”‚                                   â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                  â”‚
                                  â–¼
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚                     RAW DATA (per source)                        â”‚
    â”‚                                                                  â”‚
    â”‚   sbv_raw.json, yahoo_raw.json, investing_raw.json, ...         â”‚
    â”‚   â†’ Saved to: data/raw/{source}_{date}.json                     â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                  â”‚
                                  â–¼
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚                     TRANSFORM LAYER                              â”‚
    â”‚                                                                  â”‚
    â”‚   Raw Data â”€â”€â–¶ Transformer (per source) â”€â”€â–¶ CrawlerOutput       â”‚
    â”‚                                                                  â”‚
    â”‚   CrawlerOutput {                                                â”‚
    â”‚     source: "sbv",                                               â”‚
    â”‚     metrics: [...],    # â†’ indicators table                     â”‚
    â”‚     events: [...],     # â†’ LLM pipeline â†’ events table          â”‚
    â”‚     calendar: [...]    # â†’ calendar_events table                â”‚
    â”‚   }                                                              â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                  â”‚
                                  â–¼
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚                    LLM PROCESSING PIPELINE                       â”‚
    â”‚                    (Only for EVENTS)                             â”‚
    â”‚                                                                  â”‚
    â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
    â”‚   â”‚              LAYER 1: CLASSIFICATION                     â”‚   â”‚
    â”‚   â”‚                                                          â”‚   â”‚
    â”‚   â”‚   Input: Raw news articles                               â”‚   â”‚
    â”‚   â”‚   Output:                                                â”‚   â”‚
    â”‚   â”‚     - is_market_relevant: boolean                        â”‚   â”‚
    â”‚   â”‚     - category: monetary|fiscal|banking|...              â”‚   â”‚
    â”‚   â”‚     - linked_indicators: [indicator_ids]                 â”‚   â”‚
    â”‚   â”‚                                                          â”‚   â”‚
    â”‚   â”‚   Filter: Only relevant news â†’ Layer 2                   â”‚   â”‚
    â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
    â”‚                             â”‚                                    â”‚
    â”‚                             â–¼                                    â”‚
    â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
    â”‚   â”‚              LAYER 2: SCORING & ANALYSIS                 â”‚   â”‚
    â”‚   â”‚                                                          â”‚   â”‚
    â”‚   â”‚   Input: Classified news + Context (30 days)             â”‚   â”‚
    â”‚   â”‚   Context includes:                                      â”‚   â”‚
    â”‚   â”‚     - Open investigations                                â”‚   â”‚
    â”‚   â”‚     - Recent predictions                                 â”‚   â”‚
    â”‚   â”‚     - Hot topics                                         â”‚   â”‚
    â”‚   â”‚     - Indicator trends                                   â”‚   â”‚
    â”‚   â”‚                                                          â”‚   â”‚
    â”‚   â”‚   Output:                                                â”‚   â”‚
    â”‚   â”‚     - base_score: 1-100                                  â”‚   â”‚
    â”‚   â”‚     - score_factors breakdown                            â”‚   â”‚
    â”‚   â”‚     - causal_analysis (matched template)                 â”‚   â”‚
    â”‚   â”‚     - investigation_action (resolve/create)              â”‚   â”‚
    â”‚   â”‚     - predictions                                        â”‚   â”‚
    â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
    â”‚                             â”‚                                    â”‚
    â”‚                             â–¼                                    â”‚
    â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
    â”‚   â”‚              LAYER 3: RANKING & DECAY                    â”‚   â”‚
    â”‚   â”‚                                                          â”‚   â”‚
    â”‚   â”‚   Input: ALL active events (not just today)              â”‚   â”‚
    â”‚   â”‚                                                          â”‚   â”‚
    â”‚   â”‚   Process:                                               â”‚   â”‚
    â”‚   â”‚     1. Apply time decay (day 0: 100% â†’ day 30: 30%)     â”‚   â”‚
    â”‚   â”‚     2. Apply boost factors:                              â”‚   â”‚
    â”‚   â”‚        - Follow-up to investigation: +20%                â”‚   â”‚
    â”‚   â”‚        - Part of hot topic: +15%                         â”‚   â”‚
    â”‚   â”‚        - Multi-indicator link: +10%                      â”‚   â”‚
    â”‚   â”‚     3. Assign display_section                            â”‚   â”‚
    â”‚   â”‚     4. Identify hot topics (3+ in 7 days)               â”‚   â”‚
    â”‚   â”‚                                                          â”‚   â”‚
    â”‚   â”‚   Output:                                                â”‚   â”‚
    â”‚   â”‚     - current_score                                      â”‚   â”‚
    â”‚   â”‚     - display_section                                    â”‚   â”‚
    â”‚   â”‚     - hot_topic badge                                    â”‚   â”‚
    â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
    â”‚                                                                  â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                  â”‚
                                  â–¼
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚                        DATABASE                                  â”‚
    â”‚                                                                  â”‚
    â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
    â”‚   â”‚   indicators    â”‚  â”‚     events      â”‚  â”‚investigations â”‚   â”‚
    â”‚   â”‚   (current)     â”‚  â”‚ (analyzed news) â”‚  â”‚  (questions)  â”‚   â”‚
    â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
    â”‚            â”‚                    â”‚                   â”‚           â”‚
    â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”   â”‚
    â”‚   â”‚indicator_historyâ”‚  â”‚causal_analyses â”‚  â”‚   evidence    â”‚   â”‚
    â”‚   â”‚   (timeline)    â”‚  â”‚ (chains)       â”‚  â”‚  (timeline)   â”‚   â”‚
    â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
    â”‚                                                                  â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                  â”‚
                                  â–¼
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚                       FASTAPI SERVER                             â”‚
    â”‚                                                                  â”‚
    â”‚   /api/indicators      â†’ Dashboard indicators panel             â”‚
    â”‚   /api/events/key      â†’ Key events list                        â”‚
    â”‚   /api/events/other    â†’ Other news (collapsed)                 â”‚
    â”‚   /api/investigations  â†’ Investigation panel                    â”‚
    â”‚   /api/calendar        â†’ Economic calendar                      â”‚
    â”‚                                                                  â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                  â”‚
                                  â–¼
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚                      REACT DASHBOARD                             â”‚
    â”‚                                                                  â”‚
    â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
    â”‚   â”‚  Indicators  â”‚  â”‚  Key Events  â”‚  â”‚   Investigations     â”‚  â”‚
    â”‚   â”‚    Panel     â”‚  â”‚    List      â”‚  â”‚      Panel           â”‚  â”‚
    â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
    â”‚                                                                  â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## Detailed Step-by-Step Flow

### Step 1: Crawler Execution

```python
# scheduler.py - runs every hour
@scheduler.scheduled_job('cron', hour='*')
def hourly_job():
    run_pipeline()
```

**Raw Crawler Output** (source-specific, flat structure):
```python
# Actual SBV raw output structure
{
    "source": "sbv",
    "crawled_at": "2026-02-04T11:40:24",
    "success": True,
    "data": [
        # Flat array with 'type' field to distinguish
        {"type": "exchange_rate", "name": "USD/VND Central Rate", "value": 25067.0, ...},
        {"type": "gold_price", "name": "GiÃ¡ vÃ ng SJC", "buy_price": 177200000.0, ...},
        {"type": "policy_rate", "name": "LÃ£i suáº¥t tÃ¡i chiáº¿t kháº¥u", "value": 3.0, ...},
        {"type": "interbank_rate", "term": "Qua Ä‘Ãªm", "avg_rate": 9.12, "volume": 902773.0, ...},
        {"type": "cpi", "month": 12, "year": 2025, "mom_change": 0.19, ...},
        {"type": "omo", "transaction_type": "Mua ká»³ háº¡n", "term": "7 ngÃ y", "volume": 35983.63, ...},
        {"type": "news", "title": "Há»™i nghá»‹...", "summary": "...", "content": "...", ...}
    ],
    "count": 62
}
```

---

### Step 2: Transform Layer

**Purpose:** Convert raw source-specific data â†’ unified `CrawlerOutput` structure

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                         TRANSFORM LAYER                                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

   Raw Crawler Output              Transformer                Unified Output
   (source-specific)               (per source)               (standard)
         â”‚                              â”‚                          â”‚
         â–¼                              â–¼                          â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”           â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ sbv_raw.json    â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¶â”‚ SBVTransformer  â”‚â”€â”€â”€â”€â”€â”€â”€â–¶â”‚                 â”‚
â”‚ {               â”‚           â”‚                 â”‚        â”‚ CrawlerOutput   â”‚
â”‚   data: [...]   â”‚           â”‚ - map types     â”‚        â”‚ {               â”‚
â”‚ }               â”‚           â”‚ - aggregate OMO â”‚        â”‚   metrics: [...] â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜           â”‚ - extract news  â”‚        â”‚   events: [...]  â”‚
                              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜        â”‚   calendar: []   â”‚
                                                         â”‚ }               â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”           â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”        â”‚                 â”‚
â”‚ yahoo_raw.json  â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¶â”‚ YahooTransformerâ”‚â”€â”€â”€â”€â”€â”€â”€â–¶â”‚                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜           â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜        â”‚                 â”‚
                                                         â”‚                 â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”           â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”        â”‚                 â”‚
â”‚ investing_raw   â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¶â”‚CalendarTransformâ”‚â”€â”€â”€â”€â”€â”€â”€â–¶â”‚                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜           â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Unified CrawlerOutput Structure:**
```python
@dataclass
class CrawlerOutput:
    """Universal structure for all crawlers"""
    
    # Metadata
    source: str                    # "sbv", "investing", "yahoo"
    crawled_at: datetime
    success: bool
    error: Optional[str]
    stats: Dict[str, Any]          # Source-specific stats
    
    # The 3 core data types
    metrics: List[MetricRecord]    # Time series â†’ indicators table
    events: List[EventRecord]      # News â†’ LLM pipeline â†’ events table
    calendar: List[CalendarRecord] # Schedule â†’ calendar_events table


@dataclass
class MetricRecord:
    """Any numeric time-series data point"""
    
    metric_type: str       # "exchange_rate", "interbank_rate", "omo", "cpi", "gold_price"
    metric_id: str         # "usd_vnd_central", "interbank_on", "omo_inject"
    value: float
    unit: str              # "VND", "%", "tá»· VND"
    date: date
    period: Optional[str]  # "2025-12" for monthly, None for daily
    attributes: Dict       # volume, term, buy_price, etc.
    source: str
    source_url: Optional[str]


@dataclass  
class EventRecord:
    """News, announcements, press releases"""
    
    event_type: str        # "news", "press_release", "circular"
    title: str
    summary: Optional[str]
    content: Optional[str]
    published_at: datetime
    source: str
    source_url: Optional[str]
    language: str          # "vi", "en"


@dataclass
class CalendarRecord:
    """Future scheduled economic events"""
    
    event_name: str
    country: str           # "VN", "US", "CN"
    date: date
    time: Optional[time]
    importance: str        # "high", "medium", "low"
    previous: Optional[str]
    forecast: Optional[str]
    actual: Optional[str]
    source: str
```

**SBV Transform Example:**
```python
class SBVTransformer:
    def transform(self, raw_data: dict) -> CrawlerOutput:
        metrics = []
        events = []
        
        for item in raw_data["data"]:
            if item["type"] == "exchange_rate":
                metrics.append(MetricRecord(
                    metric_type="exchange_rate",
                    metric_id="usd_vnd_central",
                    value=item["value"],
                    unit="VND",
                    date=parse_date(item["date"]),
                    attributes={},
                    source="SBV"
                ))
            
            elif item["type"] == "interbank_rate":
                metrics.append(MetricRecord(
                    metric_type="interbank_rate",
                    metric_id=INTERBANK_TERM_MAP[item["term"]],  # "interbank_on"
                    value=item["avg_rate"],
                    unit="%",
                    date=parse_date(item["date"]),
                    attributes={"volume": item["volume"]},
                    source="SBV"
                ))
            
            elif item["type"] == "omo":
                # Aggregate by date, only use is_total=True rows
                ...
            
            elif item["type"] == "news":
                events.append(EventRecord(
                    event_type="news",
                    title=item["title"],
                    summary=item.get("summary"),
                    content=item.get("content"),
                    published_at=parse_datetime(item["date"]),
                    source="SBV",
                    source_url=item["source_url"],
                    language="vi"
                ))
        
        return CrawlerOutput(
            source="sbv",
            crawled_at=parse_datetime(raw_data["crawled_at"]),
            success=raw_data["success"],
            error=raw_data.get("error"),
            stats=raw_data["data"][0]["stats"] if raw_data["data"] else {},
            metrics=metrics,
            events=events,
            calendar=[]
        )
```

**Metric Type Mapping:**
| Raw `type` | `metric_type` | `metric_id` |
|------------|---------------|-------------|
| `exchange_rate` | `exchange_rate` | `usd_vnd_central` |
| `interbank_rate` (Qua Ä‘Ãªm) | `interbank_rate` | `interbank_on` |
| `interbank_rate` (1 Tuáº§n) | `interbank_rate` | `interbank_1w` |
| `interbank_rate` (2 Tuáº§n) | `interbank_rate` | `interbank_2w` |
| `interbank_rate` (1 ThÃ¡ng) | `interbank_rate` | `interbank_1m` |
| `policy_rate` (tÃ¡i chiáº¿t kháº¥u) | `policy_rate` | `rediscount_rate` |
| `policy_rate` (tÃ¡i cáº¥p vá»‘n) | `policy_rate` | `refinancing_rate` |
| `gold_price` (SJC) | `gold_price` | `gold_sjc` |
| `cpi` | `cpi` | `cpi_mom` |
| `omo` (aggregated) | `omo` | `omo_inject`, `omo_withdraw`, `omo_net` |

---

### Step 3: Layer 1 - Classification

**Input:** EventRecord from transform layer
**Output:** Classification result

```python
# For each event
classification = llm.generate(CLASSIFICATION_PROMPT.format(
    article=event.content or event.summary
))

# Output
{
    "is_market_relevant": True,
    "category": "monetary",
    "linked_indicators": ["interbank_on", "omo_net_daily"],
    "reasoning": "OMO operation directly affects interbank liquidity"
}
```

**Decision:**
- `is_market_relevant = True` â†’ Continue to Layer 2
- `is_market_relevant = False` â†’ Skip, don't save

---

### Step 4: Layer 2 - Scoring & Analysis

**Input:** 
- Classified news
- Previous context (30 days)

**Context Building:**
```python
context = {
    "open_investigations": [
        {
            "id": "inv_001",
            "question": "Will deposit rates increase?",
            "evidence_count": 3,
            "status": "updated"
        }
    ],
    "hot_topics": [
        {"topic": "interbank liquidity", "count": 5}
    ],
    "recent_predictions": [...],
    "indicator_trends": {
        "interbank_on": {"trend": "up", "7d_change": "+0.5%"}
    }
}
```

**Output:**
```python
{
    "base_score": 85,
    "score_factors": {
        "direct_indicator_impact": 28,  # /30
        "policy_significance": 22,       # /25
        "market_breadth": 18,            # /20
        "novelty": 10,                   # /15
        "source_authority": 7            # /10
    },
    
    "causal_analysis": {
        "matched_template_id": "omo_injection",
        "chain": [
            {"step": 1, "event": "SBV net injects via OMO", "status": "verified"},
            {"step": 2, "event": "Banking liquidity improves", "status": "likely"},
            {"step": 3, "event": "Short-term rates stabilize", "status": "uncertain"}
        ],
        "confidence": "likely"
    },
    
    "investigation_action": {
        "resolves": null,
        "creates_new": True,
        "new_investigation": {
            "question": "Will ON rate decrease tomorrow?",
            "priority": "medium"
        }
    },
    
    "predictions": [
        {
            "prediction": "ON rate may decrease to 8.5-9.0%",
            "confidence": "medium",
            "check_by_date": "2026-02-07"
        }
    ]
}
```

---

### Step 5: Layer 3 - Ranking

**Input:** ALL active events (past 30 days)

**Time Decay Formula:**
```python
def calculate_decay(age_days: int) -> float:
    if age_days == 0:
        return 1.0
    elif age_days <= 3:
        return 0.9
    elif age_days <= 7:
        return 0.7
    elif age_days <= 14:
        return 0.5
    elif age_days <= 30:
        return 0.3
    else:
        return 0  # Archive
```

**Boost Factors:**
```python
boost = 1.0
if is_follow_up_to_investigation:
    boost += 0.20
if is_hot_topic:
    boost += 0.15
if len(linked_indicators) >= 2:
    boost += 0.10
```

**Final Score:**
```python
current_score = base_score * decay_factor * boost_factor
```

**Display Section Assignment:**
```python
if current_score >= 50 and linked_indicators:
    display_section = "key_events"
elif is_market_relevant and current_score >= 20:
    display_section = "other_news"
else:
    display_section = "archive"
```

---

### Step 6: Database Storage

**Parallel Paths:**
```
CrawlerOutput
     â”‚
     â”œâ”€â”€â”€ metrics â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¶ indicators + indicator_history
     â”‚                           (direct save, no LLM)
     â”‚
     â”œâ”€â”€â”€ events â”€â”€â”€â–¶ LLM â”€â”€â”€â”€â”€â”€â–¶ events + causal_analyses + investigations
     â”‚               Pipeline    (processed through 3 layers)
     â”‚
     â””â”€â”€â”€ calendar â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¶ calendar_events
                                  (direct save, no LLM)
```

**Metrics Save Sequence:**
1. Upsert `indicators` with latest values
2. Insert into `indicator_history` if value changed from previous

**Events Save Sequence:**
1. Insert new `events` (with LLM analysis)
2. Insert `causal_analyses` for each event
3. Create/update `investigations`
4. Add `investigation_evidence`
5. Record `predictions`
6. Update `topic_frequency`

**Calendar Save Sequence:**
1. Upsert `calendar_events` (UNIQUE on date + event_name + country)

**Run History:**
```python
run_history = RunHistory(
    run_date=today,
    raw_data_path="data/raw/sbv_2026-02-05.json",
    sources_crawled=["sbv"],
    crawl_stats={
        "sbv": {"metrics": 25, "events": 20, "calendar": 0}
    },
    events_extracted=5,
    events_key=2,
    events_other=3,
    status="success"
)
```

**Deduplication:**
```python
# Events deduplicated by hash
hash = hashlib.md5(f"{title}{source}{content[:200]}".encode()).hexdigest()

# Check if exists
existing = await session.execute(
    select(Event).where(Event.hash == hash)
)
if existing.scalar():
    return  # Skip duplicate
```

---

### Step 7: API Serving

**Key Endpoints Flow:**

```
GET /api/indicators
    â†“
    Query: SELECT * FROM indicators ORDER BY category
    â†“
    Response: Grouped by category for panel display

GET /api/events/key
    â†“
    Query: SELECT * FROM events 
           WHERE display_section = 'key_events'
           ORDER BY current_score DESC
           LIMIT 15
    â†“
    Include: causal_analyses, linked indicators

GET /api/investigations
    â†“
    Query: SELECT * FROM investigations
           WHERE status IN ('open', 'updated')
           ORDER BY priority, updated_at DESC
    â†“
    Include: evidence timeline
```

---

## Investigation Lifecycle

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    INVESTIGATION LIFECYCLE                               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

   Event Analysis           New Event              New Event
   (Layer 2)                (Layer 2)              (Layer 2)
        â”‚                        â”‚                      â”‚
        â”‚ creates                â”‚ provides             â”‚ provides
        â”‚ new question           â”‚ evidence             â”‚ evidence
        â–¼                        â–¼                      â–¼
   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”             â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”           â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
   â”‚  OPEN   â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¶â”‚ UPDATED  â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¶â”‚ RESOLVED â”‚
   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   evidence  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   answer  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
        â”‚        added          â”‚         found
        â”‚                       â”‚
        â”‚ no update             â”‚ conflicting
        â”‚ > 14 days             â”‚ evidence
        â–¼                       â–¼
   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”             â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
   â”‚  STALE  â”‚             â”‚ESCALATED â”‚
   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜             â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
        â”‚                       â”‚
        â”‚ auto-close            â”‚ human review
        â–¼                       â–¼
   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”             â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
   â”‚ CLOSED  â”‚             â”‚ RESOLVED â”‚
   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜             â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                           (manual)
```

---

## Context Continuity

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      30-DAY CONTEXT WINDOW                               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

   Day -30        Day -7         Day -1          Today
      â”‚             â”‚              â”‚               â”‚
      â–¼             â–¼              â–¼               â–¼
   â”Œâ”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”       â”Œâ”€â”€â”€â”€â”€â”€â”       â”Œâ”€â”€â”€â”€â”€â”€â”
   â”‚Eventsâ”‚     â”‚Eventsâ”‚       â”‚Eventsâ”‚       â”‚ New  â”‚
   â”‚ old  â”‚     â”‚recentâ”‚       â”‚latestâ”‚       â”‚Eventsâ”‚
   â””â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”˜       â””â”€â”€â”€â”€â”€â”€â”˜       â””â”€â”€â”€â”€â”€â”€â”˜
      â”‚             â”‚              â”‚               â”‚
      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â”‚
                         â–¼
              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
              â”‚   CONTEXT SUMMARY   â”‚
              â”‚                     â”‚
              â”‚ - Open questions    â”‚
              â”‚ - Hot topics        â”‚
              â”‚ - Recurring themes  â”‚
              â”‚ - Indicator trends  â”‚
              â”‚ - Pending predictionsâ”‚
              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â”‚
                         â–¼
              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
              â”‚   LLM LAYER 2       â”‚
              â”‚   (with context)    â”‚
              â”‚                     â”‚
              â”‚ Enables:            â”‚
              â”‚ - Link to past      â”‚
              â”‚ - Resolve questions â”‚
              â”‚ - Detect patterns   â”‚
              â”‚ - Avoid redundancy  â”‚
              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## Error Handling Flow

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                       ERROR HANDLING                                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
   â”‚   Crawler   â”‚â”€â”€â”€â”€â”€â”€â–¶ Fails â”€â”€â”€â”€â”€â”€â–¶ Log error, continue with other sources
   â”‚   (Step 1)  â”‚                      Set run_history.status = 'partial'
   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
   â”‚ Transformer â”‚â”€â”€â”€â”€â”€â”€â–¶ Fails â”€â”€â”€â”€â”€â”€â–¶ Log error, skip this source
   â”‚  (Step 2)   â”‚                      Continue with other sources
   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
   â”‚    LLM      â”‚â”€â”€â”€â”€â”€â”€â–¶ Fails â”€â”€â”€â”€â”€â”€â–¶ Retry once with exponential backoff
   â”‚ (Step 3-5)  â”‚                      If still fails: save raw for manual review
   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
   â”‚  Database   â”‚â”€â”€â”€â”€â”€â”€â–¶ Fails â”€â”€â”€â”€â”€â”€â–¶ CRITICAL - stop pipeline, alert
   â”‚  (Step 6)   â”‚                      Rollback transaction
   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
   â”‚   Context   â”‚â”€â”€â”€â”€â”€â”€â–¶ Fails â”€â”€â”€â”€â”€â”€â–¶ Run with empty context, log warning
   â”‚   Build     â”‚                      Continue processing
   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## File Storage

```
data/
â”œâ”€â”€ raw/
â”‚   â”œâ”€â”€ sbv_2026-02-05.json       # Raw SBV crawler output
â”‚   â”œâ”€â”€ yahoo_2026-02-05.json     # Raw Yahoo crawler output (future)
â”‚   â””â”€â”€ investing_2026-02-05.json # Raw Investing crawler output (future)
â”‚
â”œâ”€â”€ processed/
â”‚   â””â”€â”€ 2026-02-05/
â”‚       â”œâ”€â”€ transformed.json      # After transform layer
â”‚       â”œâ”€â”€ classified.json       # Layer 1 output
â”‚       â”œâ”€â”€ scored.json           # Layer 2 output
â”‚       â””â”€â”€ ranked.json           # Layer 3 output
â”‚
â””â”€â”€ context/
    â””â”€â”€ context_summary.json      # Cached context for LLM
```

**run_history tracks:**
```python
{
    "raw_data_path": "data/raw/sbv_2026-02-05.json",
    "sources_crawled": ["sbv"],
    "crawl_stats": {
        "sbv": {
            "metrics": 25,   # exchange_rate, interbank, policy, gold, cpi, omo
            "events": 20,    # news items
            "calendar": 0,
            "errors": 0
        }
    }
}
```

---

## Extensibility Guide

### Adding a New Data Source

**Step 1: Create Crawler**
```python
# crawlers/yahoo_crawler.py
class YahooCrawler(BaseCrawler):
    def crawl(self) -> dict:
        # Return raw data in any structure
        return {
            "source": "yahoo",
            "crawled_at": datetime.now().isoformat(),
            "data": [...],  # Source-specific structure
            "success": True
        }
```

**Step 2: Create Transformer**
```python
# processor/transformers/yahoo_transformer.py
class YahooTransformer(BaseTransformer):
    def transform(self, raw_data: dict) -> CrawlerOutput:
        metrics = []
        
        for item in raw_data["data"]:
            metrics.append(MetricRecord(
                metric_type="index",
                metric_id="dxy",
                value=item["close"],
                unit="",
                date=parse_date(item["date"]),
                attributes={"open": item["open"], "high": item["high"], "low": item["low"]},
                source="Yahoo Finance"
            ))
        
        return CrawlerOutput(
            source="yahoo",
            metrics=metrics,
            events=[],
            calendar=[]
        )
```

**Step 3: Register in Pipeline**
```python
# processor/pipeline.py
CRAWLERS = {
    "sbv": SBVCrawler,
    "yahoo": YahooCrawler,      # Add new crawler
}

TRANSFORMERS = {
    "sbv": SBVTransformer,
    "yahoo": YahooTransformer,  # Add new transformer
}
```

### Adding a New Metric Type

**Step 1: Define metric_id mapping**
```python
# constants/indicator_mappings.py
INDICATOR_GROUPS = {
    "global_macro": {
        "display_name": "ðŸŒ Global",
        "indicators": [
            "dxy",          # New metric
            "us10y",        # New metric
            "fed_rate",     # New metric
        ]
    }
}
```

**Step 2: Add to transformer**
```python
# In transformer, map source data to metric_id
if item["symbol"] == "DX-Y.NYB":
    metric_id = "dxy"
elif item["symbol"] == "^TNX":
    metric_id = "us10y"
```

### Adding Calendar Data

```python
# Any crawler can return calendar data
class InvestingTransformer(BaseTransformer):
    def transform(self, raw_data: dict) -> CrawlerOutput:
        calendar = []
        
        for event in raw_data["economic_calendar"]:
            calendar.append(CalendarRecord(
                event_name=event["name"],
                country=event["country"],
                date=parse_date(event["date"]),
                time=parse_time(event["time"]) if event.get("time") else None,
                importance=event["importance"],
                previous=event.get("previous"),
                forecast=event.get("forecast"),
                source="Investing.com"
            ))
        
        return CrawlerOutput(
            source="investing",
            metrics=[],
            events=[],
            calendar=calendar  # Calendar data
        )
```

### Summary: Extension Points

| To Add... | Create/Modify |
|-----------|---------------|
| New data source | 1. Crawler, 2. Transformer, 3. Register in pipeline |
| New metric type | 1. Add to INDICATOR_GROUPS, 2. Add mapping in transformer |
| New event type | 1. Add `event_type` in EventRecord |
| New calendar source | 1. Return CalendarRecord in transformer |
